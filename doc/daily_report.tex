\documentclass[11pt,a4paper,english]{article}
\usepackage[english]{babel}
\usepackage{marginnote}
\usepackage[utf8]{inputenc}
\usepackage[top=1in]{geometry}

\usepackage{graphicx} %behandle grafikk
\usepackage{float}
\usepackage[hidelinks,colorlinks]{hyperref} %trykkbar referering
\usepackage[all]{hypcap}
\usepackage{gensymb}
\usepackage[backend=biber,style=numeric-comp]{biblatex}
\addbibresource{text_seg.bib,bib.bib}
\usepackage{todonotes} % for drafting

\newenvironment{loggentry}[2]% date, heading
{\noindent\textbf{#2}\marginnote{#1}\\}{\vspace{0.5cm}}


\title{UNIK4690 Project}
\author{
  Akhsarbek Gozoev  - akhsarbg \\
  Sadegh Hoseinpoor - sadeghh\\
  Key Lung Wong - keylw
}

\begin{document}

\maketitle
\section{Project description}
\textbf{The purpose of the software is to recognise text from any
surface with uneven lighting. Hence this falls under the ``Optical character recognition'' (OCR) problem}

\noindent \\ As OCRs are still a challenging task even for companiese like
Google, ref. reader to Googles OCR translator application on smartphones;
``Transalte'', drawbacks such as; difficulty finding all the text on the photo
becasue of lighting, noise etc., therefore we will have to limit our software
significantly.

\subsection{Initial limitations}
\begin{itemize}
 \item{English alphabet + numbers [0-9]}
 \item{Homogeneous background}
 \item{Computer printed text}
\end{itemize}

\subsection{Project components}
The group have come to the conclusion that the OCR software has 3 main
components to it.
\begin{enumerate}
 \item{\textit{Text segmentation}}
 \begin{itemize}
  \item{Finding text on an image and returning the text segments}
 \end{itemize}
 \item{\textit{Preprocessing}}
 \begin{itemize}
  \item{Do preprocessing on the segmented text; rotation, symbol segmentation,
  etc.. (preprocessing from its definition, should be done first, however
  because of simplification we assume we manage to segment out text first.)}
 \end{itemize}
 \item{\textit{Classification}}
 \begin{itemize}
  \item{Classification of the symbols}
 \end{itemize}
\end{enumerate}
\noindent \\ Additionally there is one more very important component for this
OCR software to work, \textit{\textbf{labled data}}. Even though one might not
need to code for this part, a good pool of labeled data is needed to be able to
classify symbols. More on this later.
\noindent \\ (4. \textit{Data classification - Gathering labeled data to train a classification algorithm})

\subsection{Component description}
This section we will describe our thoughts on how we plan to solve each
component, in the form of algorithms, APIs, and datasets. Note that this is our
initial thoughts, not necessary the solution we will end up implementing.

\noindent \\ As we want to test proof-of-concept while we are coding, we will
be making several simplifications. These simplifications will be described
further under each component.



\subsubsection{Text Segmentation}
\noindent \\ \textbf{Description}
\noindent \\ We where uncertain on how to do this part when we initial started the project. We ended up looking for alot of different ways to do this part. We ended up trying 3 different approaches with mix result. 
\begin{enumerate}
  \item Simple image analysis technics, using Otsu tresholding and Morphologi.
  \item OpenCv imprementation of Scene Text Detection.
  \item Stride Width Transform(SWT) to detect text in natural images.
\end{enumerate}

\noindent \\ \textbf{Approach 1: Simple Image Analysis Technics}
\noindent \\ We was inspired by the this online blog \href{https://www.danvk.org/2015/01/07/finding-blocks-of-text-in-an-image-using-python-opencv-and-numpy.html}{Source}\cite{_finding_????}. We simplified the original approach where we only look at an image with text. The approach is then simply do an Otsu Tresholding and then morphological Closing to connect component. After thet we used OpenCv FindContours method to find the countour of the different text regions. FindContours in Opencv uses the algorithm proposed by Suzuki, S. and Abe, K. 1985\cite{suzuki_topological_????}. 

\noindent \\ \textbf{Approach 2: OpenCv Scene Text Detection}
\noindent \\ OpenCV have it own Text Scene Detection. The approach of this algorithm is to detect text in scene using Classifier and Components Tree, propose by Luk√°s Neumann \& Jiri Matas \cite{neumann_real-time_2012}.

\noindent \\ \textbf{Approach 3: Stroke Width Transform}
\noindent \\ We also found Stroke Width Tranform to do Text Segmentation\cite{epshtein_stroke_2010}. Similar to OpenCv Scene text detection, it looks for text in natural images. The approach of the Algorithm is to calculate the different stroke length of the different elements in the image. Based on the stroke lenght, evaluate if it is a text element or not. The concept was relativ simple to grasp. The implementation, in the other hand, was quite difficult to implement. We will look at the full implemtation later in. 

\subsubsection{Preprocessing}
\todo[inline]{
\noindent \\ \textbf{Description}
\noindent \\
. \\
. \\
. \\
. \\
. \\
}


\subsubsection{Classification}
\noindent \\ \textbf{Description}
\noindent \\ At this point because of avalible knowledge and the intrest in
Convolutional Neural network (CNN), we ended up trying to solve this part
both with a CNN, and a Multilayer Peceptron (MLP or Deep neural network (DNN)).
Illustration of each of the architectures are avalible, CNN Figure~\ref{fig:CNN_architecture},
and the MLP network Figure~\ref{fig:neural_net2}. \par
To avoid inventing the wheel again, we will use the TensoerFlow API, the low
level API will suffice for the MLP, and the HIGH level API we will try for the
CNN.

\noindent \\ \textbf{Deep Neural Network}
\noindent \\ Multilayer peceptron neural networks are relatively straight
forward to code, however the challinging part is to decide on good
hyperparameters and to not overfit our network. \par
Reasearch has showen that the choices of parameters can have huge effects on
the error rate thorugh empirical testing. As emperical testing has showen that
some combinations of parameters are better than others, we will also use the
same method to find decent values on several of the hyperparameters. More on
this below, where a short discription of the hyperparameters follow. \par
One obvious disadvantage we might face by using MLP is that slight spatial
change on where in the image the characters are located, might lead to
characters classified diffrently. This is because there is no spatial
connections on a MLP.

\begin{figure}[H]
  \centering
  \includegraphics[height=4cm]{res/neural_net2.jpeg}
  \caption{MLP Neural netowrk. \href{http://cs231n.github.io/neural-networks-1/}{Source}}
  \label{fig:neural_net2}
\end{figure}



\noindent \\
\noindent \\ \textbf{Hyperparameters}
\begin{itemize}
 \item{Number of hidden layers}
 \begin{itemize}
  \item{Layers decide how well the software can define the decision borders.
  Hence increase in layers can have a positive effect, there are aslo cons with
  the amount of layers. The more layers, the greater the computational power
  needed to train the system. We will be useing the empirical method to decide
  how many layers we need}
 \end{itemize}
 \item{Number of nodes in each hidden layer}
 \begin{itemize}
  \item{Nodes in each hidden layer has the same effect as the number of hidden
  layers, hence the same applies for this hyperparameter. }
 \end{itemize}
 \item{Activation functions}
 \begin{itemize}
  \item{The activation function decides which combination of nodes, with their
  signals, are allowed to propogate through the network. Here we will be using
  the \textit{rectified linear unit} (RELU) activation function. This is an
  activation function that allows propogation if the signal is positive,
  othervise it will forward a zero. The reason for choosing this activation
  function is because this function handels the \textit{vanishing gradient
  problem} better than sigmoid and atanh activation functions. More on
  vanishing gradient problem under ``optimization function''.}
 \end{itemize}
 \item{Loss function}
 \begin{itemize}
  \item{The loss function describes how far off the predicted class of the
  character is from the real class. In our case since we have multiple
  classes and we are going to use \textit{softmax regression} as the output
  layer, we also will be using the \textit{cross-entropy loss function}.}
 \end{itemize}
 \item{Optimization function}
 \begin{itemize}
  \item{The backpropogation will train the weights by Gradient Decent
  Optimization. However as training with several thousand examples, and then
  optimizing the weights and run the training process, is too costly resource
  wise, we will have to implement the \textit{mini-batch gradient decent
  optimizations}. Same principle as gradient decent optimization, but this way
  we will find the gradient decent for each batch. As long as these batches are
  randomly choosen, and the sizes are large enough, (we will be using 100 as
  batch size), these will represent the entire dataset well enough.}
 \end{itemize}
 \item{Learning rate}
 \begin{itemize}
  \item{Learning rate is a scalar that decides how large the stepts towards
  the gradient minimum will be, for the weights. Choosing too small of a
  learningrate we might risk not reaching the bottom of the graph, we also
  might get stuck in a local minimum. Choosing too large of a learning rate
  we might risk never settle down on a minimum. \par
  For the learning rate we will be useing the empirical method too.}
 \end{itemize}
 \item{Initialization of the weights and biases}
 \begin{itemize}
  \item{Initialization of the weights also seems to be of importance,
  researchers have found out. This is obvious, as for example setting all the
  weights to zero, would of course lead to a network with very few active
  nodes. \par
  We will be using the initialization of zeros for the biases, not any
  apperant reason. Based on our reasearch, it seems people have gotten decent
  results when using this initialization. For the weights we will be using a
  gaussian distribution, mean=0, standard diviation=1. Again this is aslo
  something that we have read should be a good initialization for the weights,
  no other reason.}
 \end{itemize}
 \item{Number of epochs}
 \begin{itemize}
  \item{Number of epochs are only relevant when we have a small number of
  dataset. When we have a small dataset we might want to run the software on
  the same dataset several times. This might result in overfitting the software
  to the dataset, therefore it is really important to be carfull of the number of
  epochs, in cases with small datasets.}
 \end{itemize}
\end{itemize}


\noindent \\ \textbf{Convolutional Neural Network}
\noindent \\ Convolutional neural networks are especially good for image
classification because they takes into account local spatial connections. This
way it dosent matter where in the image our object/character is it will be
able to recognise it. CNNs are also rotation invariant, hence the
classification would be even more robust.


\begin{figure}[H]
  \centering
  \includegraphics[height=4cm]{res/CNN_architecture.png}
  \caption{MLP Neural netowrk. \href{ http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/}{Source}}
  \label{fig:CNN_architecture}
\end{figure}

\noindent \\ \textbf{Limitation - proof of concept}
\todo[inline]{
\noindent \\ \textbf{Description}
\noindent \\
. \\
. \\
. \\
. \\
. \\
}

\subsubsection{Labled Data}
\noindent \\ \textbf{Description}
\noindent \\
Labled data is needed because our classifiers need to be trained to understand
the difference between the charecters. This is usually done by training a
classifier with a set of training data, labels are needed in our case,
since it is a supervised machine learning algorithm we want to use. As the
training data is used to train the software, we will need data to test our
software as well, hence the need for test data. The test data is used to get a
measure of what the error rate of our software is, based on the results we
can then tune the hyperparameters to get a better/smaller error rate. Lastly
we will need validation data. This is an independent dataset that the software
is not familiar with. The accuracy of the software on the validation set will
then be a measure of how good the software can classify the characters.

\noindent \\ \textbf{Limitation - proof of concept}
\noindent \\
As we have limited us to the English alphabet and numbers ranging from [0-9],
we will need labeled data for each of these 36 characters; training, test and
validation sets. As the concept of classifying only numbers vs all 36
charecters does not differ that much, we will first see if we can solve the OCR
problem with just numbers. Therfore we only need a dataset containing numbers
at first. Thereafter we will search for a dataset containing all the characters
we need.

\noindent \\ \textbf{Dataset}
\noindent \\
\noindent \\ \textbf{MNIST}
\noindent \\ This is a dataset containing handwritten numbers [0-9].
It has a training set of 60.000 examples and a test set of 10.000 examples.
(ref. reader to http://yann.lecun.com/exdb/mnist/).










%\begin{itemize}
% \item{}
%\end{itemize}













\newpage
\section*{Report}
\begin{loggentry}{19.04.18}{Week 1}
\begin{itemize}
  \item{Feedback on project proposal}
  \item{Overview of project}
    \begin{itemize}
     \item{simplification}
     \item{binary image $\rightarrow$ numbers $\rightarrow$ straight text $\rightarrow$ Classify}
   \end{itemize}
  \item{init; github - atom}
  \item{first test of charcter Segmentation}
\end{itemize}
\end{loggentry}


\newpage
\begin{loggentry}{26.04.18}{Week 2}
\begin{itemize}
  \item{Charcter Segmentation - Projection Histograms - OpenCV}
  \begin{itemize}
    \item{By projection the histogram of the binary image on the Y-axis,
    we can find where the sentences/lines of text appears. Following, a
    projection histogram on the X-axis can discover where the charecters
    appear.}
  \end{itemize}

  \begin{figure}[H]
    \centering
    \includegraphics[height=4cm]{res/0-9_segmented_out.png}
    \caption{[0-9] segmented with projection histogram}
    \label{fig:0-9_segmented_out}
  \end{figure}

  \item{Classification - Perceptron neural network - TensorFlow}
    \begin{itemize}
      \item{MNIST dataset - Datasett consisting of several thousand handwritten
      labeled numbers}
      \begin{itemize}
        \item{Numbers ranging from [0-9]}
        \item{Images are 28x28pixels}
      \end{itemize}
      \item{Hyperparameter tuneing}
      \begin{itemize}
        \item{Activation function}
        \item{Number of hidden layers}
        \item{Nodes in hidden layers}
        \item{Cost function}
        \item{Optimization function}
        \item{Learning rate}
      \end{itemize}
      \item{Theoretic accuracy of the network with 2 hidden layers ~98\%}
      \begin{itemize}
        \item{Measured accuracy ~97\%}

        \begin{figure}[H]
          \centering
          \includegraphics[height=1cm]{res/classification_first_print.png}
          \caption{First output with classification. input see Figure ~\ref{fig:0-9_segmented_out}}
          \label{fig:classification_first_print}
        \end{figure}

      \end{itemize}
    \end{itemize}
\end{itemize}
\end{loggentry}


\newpage
\begin{loggentry}{03.05.18}{Week 3}
\begin{itemize}
  \item{Rotation of text}
  \begin{itemize}
    \item{Hough transform}
    \item{\textit{cv2.minAreaRect()}}
  \end{itemize}
  \item{How to distinguish between upside-down, and verticle vs horisontal text segments}
  \begin{itemize}
    \item{Classifiy in all 4 rotations, and choose the classification with highest avrage confidence}
  \end{itemize}
  \item{Classification - Perceptron neural network - Error}
  \begin{itemize}
    \item{Error rate too high, test-set accuracy 97\%, validation set accuracy $<$ 50\%}
    \item{CNN - TensorFlow Estimator API}
    \begin{itemize}
      \item{Challenging documantation; load/save models}
    \end{itemize}
    \item{Dataset - FNIST - Group contribution}
    \begin{itemize}
      \item{Dataset including several fonts}
      \item{English alphabet, and numbers [0-9]}
    \end{itemize}
  \end{itemize}
\end{itemize}
\end{loggentry}

\newpage
\begin{loggentry}{17.05.18}{Week 4}
\begin{itemize}
  \item{-----}
  \begin{itemize}
    \item{-----}
    \item{-----}
  \end{itemize}
  \item{------}
\end{itemize}
\end{loggentry}

\end{document}
